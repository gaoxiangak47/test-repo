{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Medicare Fraud Detection\n",
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Medicare provides health insurance for Americans aged 65 and older, younger people with some disabilities, as well as people with end stage disease. The authority has a list of excluded individuals and entities from healthcare program for reasons including conviction or fraud. \n",
    "\n",
    "The project is based on medicare part D prescription drug program data in 2013, which contains npi(physician,pharmacy id), prescription and patients information. I labeled the Npi appeared in the exclusion list in 2014 as the positive class. Then build classification models to detect the fraud.\n",
    "\n",
    "The data is imbalanced with a fraud percentage of `0.25%` with ~1M records. In order to solve this issue, one way is to use LightGBM `scale_pos_weight` to apply weights on positive data and this model gives the accuracy at `0.72`. The second method is to downsample the negative class to make the two classes size equal. I built a logistic regression model and the accuracy boosted to`0.75`. Another popular way is to oversample the positive class. However, there are discussions that it is not a good approach for extremely imbalanced data. By doing some research I found a Talking Data Fraud Detection project on Kaggle which also has a similar imbalanced data with `0.24%` positive class. The winning solution is using downsampling.\n",
    "\n",
    "For further model improvement, I will use `SMOTE` to oversample and apply `SGDClassifier` model which is proven efficient on large datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.997427\n",
       "1    0.002573\n",
       "Name: is_fraud, dtype: float64"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "data = pd.read_csv('medicare-provider-utilization-and-payment-data-part-d-prescriber-summary-table-cy2013-1.csv')\n",
    "data_deactivate = pd.read_csv('nppes-deactivated-npi-report_1.csv')\n",
    "data['is_fraud'] = data['npi'].isin(data_deactivate['NPI']) *1\n",
    "\n",
    "#data imbalance\n",
    "data['is_fraud'].value_counts(normalize = True) # similar to Kaggle Talking data fraud detection .0024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'null values ratio')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1b98a3c0208>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Preliminary feature selection, eliminate address, names, organization, provider's gender\n",
    "column_filter = pd.read_csv('medi_column_filter.csv',header = 0)\n",
    "data = data[column_filter['header'].values]\n",
    "\n",
    "# check null values percentage\n",
    "null_ratio = data.isnull().sum()/data.shape[0]\n",
    "null_ratio.plot('hist')\n",
    "plt.title('null values ratio')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see 0.4 is a good cutoff as most of features are below it. The feature with more than 40% null values will be removed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filling na and transform categorical into integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We can see 0.4 is a good cutoff as most of features are below it\n",
    "data = data[null_ratio[null_ratio<=0.4].index.values]\n",
    "#Fill numerical colums will 0, non-numerical with 'NA'\n",
    "float_cols = data.select_dtypes(exclude=['object']).columns\n",
    "str_cols = data.select_dtypes(include=['object']).columns\n",
    "data.loc[:, float_cols] = data.loc[:, float_cols].fillna(data.loc[:, float_cols].mean())\n",
    "data.loc[:, str_cols] = data.loc[:, str_cols].fillna('NA')\n",
    "#Encoding categorical columns\n",
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "for i in str_cols:\n",
    "    data[i] = le.fit_transform(data[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling using LightGBM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is imbalanced. One way to deal with it is using LightGBM `scale_pos_weight` to apply weight on positive labels. When choosing the metric, ROC and F1 score are more invariant to imbalanced data because TPR and FPR are calculated for each class separately. AUC is chosen in this project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "import time\n",
    "\n",
    "def lgb_modelfit_nocv(params, dtrain, dvalid, predictors, target='target', objective='binary', metrics='auc',\n",
    "                 feval=None, early_stopping_rounds=20, num_boost_round=3000, verbose_eval=10, categorical_features=None):\n",
    "    lgb_params = {\n",
    "        'boosting_type': 'gbdt',\n",
    "        'objective': objective,\n",
    "        'metric':metrics,\n",
    "        'learning_rate': 0.01,\n",
    "        'num_leaves': 15,  # we should let it be smaller than 2^(max_depth)\n",
    "        'max_depth': 5,  # -1 means no limit\n",
    "        'min_child_samples': 20,  # Minimum number of data need in a child(min_data_in_leaf)\n",
    "        'max_bin': 255,  # Number of bucketed bin for feature values\n",
    "        'subsample': 0.6,  # Subsample ratio of the training instance.\n",
    "        'subsample_freq': 0,  # frequence of subsample, <=0 means no enable\n",
    "        'colsample_bytree': 0.3,  # Subsample ratio of columns when constructing each tree.\n",
    "        'min_child_weight': 5,  # Minimum sum of instance weight(hessian) needed in a child(leaf)\n",
    "        'subsample_for_bin': 200,  # Number of samples for constructing bin\n",
    "        'min_split_gain': 0,  # lambda_l1, lambda_l2 and min_gain_to_split to regularization\n",
    "        'reg_alpha': 0,  # L1 regularization term on weights\n",
    "        'reg_lambda': 0,  # L2 regularization term on weights\n",
    "        'nthread': 4,\n",
    "        'verbose': 0,\n",
    "        'metric':metrics,\n",
    "    }\n",
    "\n",
    "    lgb_params.update(params)\n",
    "\n",
    "    print(\"preparing validation datasets\")\n",
    "\n",
    "    xgtrain = lgb.Dataset(dtrain[predictors].values, label=dtrain[target].values,\n",
    "                          feature_name=predictors,\n",
    "                          categorical_feature=categorical_features\n",
    "                          )\n",
    "    xgvalid = lgb.Dataset(dvalid[predictors].values, label=dvalid[target].values,\n",
    "                          feature_name=predictors,\n",
    "                          categorical_feature=categorical_features\n",
    "                          )\n",
    "\n",
    "    evals_results = {}\n",
    "\n",
    "    bst1 = lgb.train(lgb_params, \n",
    "                     xgtrain, \n",
    "                     valid_sets=[xgtrain, xgvalid], \n",
    "                     valid_names=['train','valid'], \n",
    "                     evals_result=evals_results, \n",
    "                     num_boost_round=num_boost_round,\n",
    "                     early_stopping_rounds=early_stopping_rounds,\n",
    "                     verbose_eval=10, \n",
    "                     feval=feval)\n",
    "\n",
    "    return bst1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train, validation, test data split\n",
    "len_train = int(len(data)*0.8)\n",
    "test_df = data[len_train:]\n",
    "val_df = data[(len_train-int(len_train*0.8)):len_train]\n",
    "train_df = data[:(len_train-int(len_train*0.8))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove predictor Npi, speficy categorical columns (lgb can deal with categorical directly)\n",
    "target = 'is_fraud'\n",
    "predictors = list(train_df.columns.values[1:])\n",
    "categorical = list(str_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'learning_rate': 0.08,\n",
    "    #'is_unbalance': 'true', # replaced with scale_pos_weight argument\n",
    "    'num_leaves': 7,  # 2^max_depth - 1\n",
    "    'max_depth': 3,  # -1 means no limit\n",
    "    'min_child_samples': 100,  # Minimum number of data need in a child(min_data_in_leaf)\n",
    "    'max_bin': 100,  # Number of bucketed bin for feature values\n",
    "    'subsample': 0.7,  # Subsample ratio of the training instance.\n",
    "    'subsample_freq': 1,  # frequence of subsample, <=0 means no enable\n",
    "    'colsample_bytree': 0.9,  # Subsample ratio of columns when constructing each tree.\n",
    "    'min_child_weight': 0,  # Minimum sum of instance weight(hessian) needed in a child(leaf)\n",
    "    'scale_pos_weight':50 # because training data is extremely unbalanced \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "preparing validation datasets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\xgao\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py:1027: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n",
      "C:\\Users\\xgao\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py:668: UserWarning: categorical_feature in param dict is overrided.\n",
      "  warnings.warn('categorical_feature in param dict is overrided.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 30 rounds.\n",
      "[10]\ttrain's auc: 0.732662\tvalid's auc: 0.692506\n",
      "[20]\ttrain's auc: 0.746387\tvalid's auc: 0.702089\n",
      "[30]\ttrain's auc: 0.77248\tvalid's auc: 0.711988\n",
      "[40]\ttrain's auc: 0.790867\tvalid's auc: 0.714371\n",
      "[50]\ttrain's auc: 0.808252\tvalid's auc: 0.717673\n",
      "[60]\ttrain's auc: 0.823907\tvalid's auc: 0.720401\n",
      "[70]\ttrain's auc: 0.837432\tvalid's auc: 0.72159\n",
      "[80]\ttrain's auc: 0.844546\tvalid's auc: 0.722327\n",
      "[90]\ttrain's auc: 0.854993\tvalid's auc: 0.723491\n",
      "[100]\ttrain's auc: 0.865195\tvalid's auc: 0.722641\n",
      "[110]\ttrain's auc: 0.874081\tvalid's auc: 0.722994\n",
      "[120]\ttrain's auc: 0.880871\tvalid's auc: 0.722819\n",
      "Early stopping, best iteration is:\n",
      "[91]\ttrain's auc: 0.855856\tvalid's auc: 0.723516\n",
      "[15.234267234802246]: model training time\n"
     ]
    }
   ],
   "source": [
    "#train the model\n",
    "print(\"Training...\")\n",
    "start_time = time.time()\n",
    "\n",
    "bst = lgb_modelfit_nocv(params, \n",
    "                        train_df, \n",
    "                        val_df, \n",
    "                        predictors, \n",
    "                        target, \n",
    "                        objective='binary', \n",
    "                        metrics='auc',\n",
    "                         early_stopping_rounds=30, \n",
    "                        verbose_eval=True, \n",
    "                        num_boost_round=500, \n",
    "                        categorical_features=categorical)\n",
    "\n",
    "print('[{}]: model training time'.format(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Result on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7274070077732018"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test result\n",
    "from sklearn import metrics\n",
    "y = test_df['is_fraud']\n",
    "pred = bst.predict(test_df[predictors])\n",
    "fpr,tpr,thresholds = metrics.roc_curve(y,pred)\n",
    "model1 = metrics.auc(fpr,tpr)\n",
    "model1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downsample\n",
    "Another method is to downsample the negative class and make the two classes size equal. Then build a logistic regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class0_id = np.where(data['is_fraud']==0)[0]\n",
    "class1_id = np.where(data['is_fraud']==1)[0]\n",
    "n_class0 = len(class0_id)\n",
    "n_class1 = len(class1_id)\n",
    "np.random.seed(21619)\n",
    "down_sample = np.random.choice(class0_id, size = n_class1, replace = False)\n",
    "id_all = np.hstack((class1_id, down_sample))\n",
    "data_balance = data[data.index.isin(id_all)]\n",
    "#shuffle data\n",
    "data = data_balance.sample(frac = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train, validation, test data split\n",
    "len_train = int(len(data)*0.8)\n",
    "test_df = data[len_train:]\n",
    "train_df = data[:len_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\xgao\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\xgao\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7555688930806825"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "\n",
    "logreg = LogisticRegression()\n",
    "Xtrain = train_df[predictors]\n",
    "ytrain = train_df['is_fraud']\n",
    "logreg.fit(Xtrain, ytrain)\n",
    "\n",
    "#test result\n",
    "from sklearn import metrics\n",
    "y = test_df['is_fraud']\n",
    "pred = logreg.predict(test_df[predictors])\n",
    "fpr,tpr,thresholds = metrics.roc_curve(y,pred)\n",
    "model2 = metrics.auc(fpr,tpr)\n",
    "model2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Oversample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will use SMOTE algorithm which randomly chooses one of the k neareast neighbors and uses it to create a similar but tweaked observation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "len_train = int(len(data)*0.8)\n",
    "test_df = data[len_train:]\n",
    "train_df = data[:len_train]\n",
    "\n",
    "Xtrain = train_df[predictors]\n",
    "ytrain = train_df['is_fraud']\n",
    "\n",
    "os = SMOTE(random_state = 21619)\n",
    "os_X,os_y = os.fit_sample(Xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we oversample, we have 2M records now. `SGDclassifier`is proven to be efficient in large scale datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "clf = SGDClassifier(loss = 'hinge',penalty = 'l2',max_iter=10000,alpha = 1)\n",
    "clf.fit(os_X,os_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reference and data source"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Detecting Medicare Fraud](https://blog.dataiku.com/2015/08/12/medicare-fraud)\n",
    "\n",
    "[Npi deactivation list 2014](https://data.world/cms/qbms-kuqs)\n",
    "\n",
    "[Medicare provider utilization and payment data](https://data.world/cms/cks9-s5d9)\n",
    "\n",
    "[Data description](https://data.cms.gov/Medicare-Part-D/Medicare-Provider-Utilization-and-Payment-Data-Par/cks9-s5d9)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
